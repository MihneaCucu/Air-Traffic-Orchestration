# SAC (Soft Actor-Critic) pentru ATC Environment

## ğŸ“‹ Cuprins
- [Ce este SAC?](#ce-este-sac)
- [Structura FiÈ™ierelor](#structura-fiÈ™ierelor)
- [Instalare & Setup](#instalare--setup)
- [Cum sÄƒ Rulezi SAC](#cum-sÄƒ-rulezi-sac)
- [Modele Antrenate](#modele-antrenate)
- [Troubleshooting](#troubleshooting)
- [FAQ](#faq)

---

## ğŸ¤– Ce este SAC?

**SAC (Soft Actor-Critic)** este un algoritm de reinforcement learning off-policy care:
- âœ… MaximizeazÄƒ reward-ul È˜I entropia (explorare inteligentÄƒ)
- âœ… Este foarte stable la training
- âœ… FuncÈ›ioneazÄƒ bine pentru continuous È™i discrete action spaces
- âœ… Are automatic temperature tuning

### Avantajele SAC vs alte algoritme:
| CaracteristicÄƒ | SAC | PPO | DQN |
|----------------|-----|-----|-----|
| Sample efficiency | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ |
| Stabilitate | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ |
| Explorare | â­â­â­â­â­ | â­â­â­ | â­â­ |
| VitezÄƒ training | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ |

---

## ğŸ“ Structura FiÈ™ierelor

```
Project/
â”œâ”€â”€ sac_agent.py          # Implementarea SAC (agent + reÈ›ele)
â”œâ”€â”€ train_sac.py          # Script pentru antrenament
â”œâ”€â”€ eval_sac.py           # Script pentru evaluare
â”œâ”€â”€ test_sac.py           # Script pentru testare componente
â”œâ”€â”€ visualize_sac.py      # Script pentru vizualizare cu rendering
â”œâ”€â”€ atc_env.py            # Environment-ul ATC
â””â”€â”€ models/               # Directorul cu modele
    â”œâ”€â”€ sac_atc.pth      # Model final (ultima versiune)
    â”œâ”€â”€ sac_atc_best.pth # Best model (cel mai bun reward)
    â””â”€â”€ sac_checkpoints/ # Checkpoint-uri la fiecare 50k steps
        â”œâ”€â”€ sac_atc_50000.pth
        â”œâ”€â”€ sac_atc_100000.pth
        â”œâ”€â”€ ...
        â””â”€â”€ sac_atc_500000.pth
```

---

## ğŸ”§ Instalare & Setup

### 1. ActiveazÄƒ Virtual Environment

```bash
cd /Users/mihneacucu/Documents/RL/Project
source venv/bin/activate
```

### 2. VerificÄƒ DependenÈ›ele

AsigurÄƒ-te cÄƒ ai instalate:
```bash
pip install torch numpy pygame gymnasium
```

### 3. VerificÄƒ cÄƒ Totul FuncÈ›ioneazÄƒ

```bash
python test_sac.py
```

DacÄƒ vezi `âœ… ALL TESTS PASSED!`, eÈ™ti gata!

---

## ğŸš€ Cum sÄƒ Rulezi SAC

### ğŸ“Š **1. EVALUARE (Recomandat sÄƒ Ã®ncepi cu asta!)**

#### EvalueazÄƒ Best Model (recomandat)
```bash
python eval_sac.py --best
```

Acesta este **cel mai bun model** salvat Ã®n timpul antrenamentului.

#### EvalueazÄƒ Model Final
```bash
python eval_sac.py
```

#### Evaluare ExtinsÄƒ (mai multe episoade)
```bash
python eval_sac.py --best --episodes 50
```

#### ComparÄƒ Toate Modelele
```bash
python eval_sac.py --compare
```

ComparÄƒ modelul final, best model È™i toate checkpoint-urile!

#### Evaluare cu Render (Vezi agentul Ã®n acÈ›iune)
```bash
python eval_sac.py --best --render --episodes 5
```

**Output-ul aratÄƒ:**
```
======================================================================
EVALUARE SAC AGENT
======================================================================
Model: models/sac_atc_best.pth
Device: cpu
...
======================================================================
ğŸ“Š REZULTATE EVALUARE
======================================================================
Episoade evaluate: 100

Reward Statistics:
  Mean Reward:    156.34 Â± 45.21
  Min Reward:     -23.45
  Max Reward:     287.90

Episode Statistics:
  Mean Length:    198.45 Â± 23.12
  Success Rate:    78.0% (78/100)
======================================================================
```

---

### ğŸ¬ **2. VIZUALIZARE (Vezi agentul cum joacÄƒ)**

#### Vizualizare Best Model
```bash
python visualize_sac.py --best
```

Deschide o fereastrÄƒ pygame È™i vezi agentul SAC controlÃ¢nd avioanele Ã®n timp real!

#### Vizualizare cu Mai Multe Episoade
```bash
python visualize_sac.py --best --episodes 10
```

#### Vizualizare Ã®n Slow Motion (pentru debugging)
```bash
python visualize_sac.py --best --speed slow
```

#### OpÈ›iuni de vitezÄƒ:
- `--speed slow` - 5 FPS (pentru analizÄƒ detaliatÄƒ)
- `--speed normal` - 10 FPS (default)
- `--speed fast` - 20 FPS (rapid)

**Output:**
```
======================================================================
VIZUALIZARE AGENT SAC
======================================================================
Episoade: 5
Render speed: normal (10 FPS)
======================================================================

â¸ï¸  Ãnchide fereastra pentru a opri vizualizarea

======================================================================
ğŸ“º EPISOD 1/5
======================================================================
  Step 50: Reward=2.50, Total Score=125.30
  Step 100: Reward=3.20, Total Score=245.80

âœ“ SUCCESS
  Final Score: 267.45
  Steps: 127
======================================================================
```

---

### ğŸ‹ï¸ **3. ANTRENAMENT (DacÄƒ vrei sÄƒ antrenezi din nou)**

âš ï¸ **ATENÈšIE**: Deja ai modele antrenate! Antrenamentul va suprascrie modelele existente!

#### Quick Training (testare rapidÄƒ, ~10-15 min)
```bash
python train_sac.py --quick
```
- 100,000 steps
- Perfect pentru testare rapidÄƒ

#### Full Training (recomandat, ~1-2 ore)
```bash
python train_sac.py
```
- 500,000 steps
- Balansat Ã®ntre timp È™i performanÈ›Äƒ

#### Long Training (pentru cei mai buni rezultate, ~3-4 ore)
```bash
python train_sac.py --long
```
- 1,000,000 steps
- Cea mai bunÄƒ performanÈ›Äƒ

#### Training Custom
```bash
python train_sac.py --timesteps 750000
```

**Output Ã®n timpul training-ului:**
```
======================================================================
ANTRENAMENT SAC PENTRU ATC ENVIRONMENT
======================================================================
Device: cpu
Total timesteps: 500,000
Learning starts: 10,000
Batch size: 256
Buffer size: 1,000,000
======================================================================

ğŸš€ Starting training...
ğŸ“Š Logs: atc_logs/sac_training_20260114-123456.log
----------------------------------------------------------------------
Episode   10 | Step    2847 | Reward:  -45.23 | Avg(10):  -52.34 | Len: 284 | Q1Loss: 0.1234 | PolLoss: 0.0456
Episode   20 | Step    5821 | Reward:   12.45 | Avg(10):   -8.91 | Len: 297 | Q1Loss: 0.0987 | PolLoss: 0.0389

======================================================================
ğŸ“Š EVALUATION at step 10,000
----------------------------------------------------------------------
Mean Reward: 45.67
Mean Length: 189.34
Success Rate: 34.0%
======================================================================

ğŸ† New best model! Saved to models/sac_atc_best.pth
...
```

---

## ğŸ“¦ Modele Antrenate

### DiferenÈ›a Ã®ntre Modele

#### `sac_atc.pth` - Model Final
- âœ… Ultima versiune salvatÄƒ la sfÃ¢rÈ™itul antrenamentului
- âš ï¸ Poate sÄƒ **nu fie** cea mai bunÄƒ versiune
- ğŸ“ FoloseÈ™te doar dacÄƒ vrei sÄƒ continui training-ul

#### `sac_atc_best.pth` - Best Model â­ **RECOMANDAT**
- âœ… Modelul cu **cel mai mare reward mediu** Ã®n evaluare
- âœ… Salvat automat cÃ¢nd agentul atinge record nou
- âœ… **Cel mai bun pentru evaluare È™i deployment**
- ğŸ¯ **FoloseÈ™te Ã®ntotdeauna acesta pentru demonstraÈ›ii!**

#### `sac_checkpoints/sac_atc_*.pth` - Checkpoint-uri
- âœ… Salvate la fiecare 50,000 steps
- âœ… Utile pentru:
  - Comparare progres
  - Recovery dacÄƒ training-ul se Ã®ntrerupe
  - AnalizÄƒ evoluÈ›ie agent

### Cum Verific Ce Modele Am?

```bash
# Vezi modelele principale
ls -lh models/sac_atc*.pth

# Vezi toate checkpoint-urile
ls -lh models/sac_checkpoints/

# Sau foloseÈ™te eval pentru comparaÈ›ie
python eval_sac.py --compare
```

---

## ğŸ§ª Testare

### Test Rapid Componente
```bash
python test_sac.py
```

VerificÄƒ:
- âœ… Environment funcÈ›ioneazÄƒ
- âœ… Replay buffer funcÈ›ioneazÄƒ
- âœ… Agent se poate crea
- âœ… Training loop funcÈ›ioneazÄƒ

### Test Quick Training (1000 steps)
```bash
python test_sac.py
```

---

## ğŸ”§ Troubleshooting

### Problema: Scriptul se blocheazÄƒ la Ã®ncÄƒrcare

**CauzÄƒ**: PyTorch are probleme de threading pe macOS cu Python 3.13

**SoluÈ›ie**: Toate scripturile au fost patches cu:
```python
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'
torch.set_num_threads(1)
```

DacÄƒ tot nu merge:
```bash
# ReinstaleazÄƒ PyTorch
pip uninstall torch
pip install torch --no-cache-dir

# SAU downgrade la Python 3.11
conda create -n rl-py311 python=3.11
conda activate rl-py311
pip install torch numpy pygame gymnasium
```

### Problema: "Model nu a fost gÄƒsit"

**VerificÄƒ**:
```bash
ls -la models/sac_atc*.pth
```

**DacÄƒ lipsesc**: FoloseÈ™te un checkpoint:
```bash
cp models/sac_checkpoints/sac_atc_500000.pth models/sac_atc_best.pth
```

### Problema: Pygame warning despre pkg_resources

**Nu este o problemÄƒ!** Este doar un warning. Scriptul va funcÈ›iona normal.

### Problema: Import error "No module named 'sac_agent'"

**SoluÈ›ie**: AsigurÄƒ-te cÄƒ rulezi din directorul corect:
```bash
cd /Users/mihneacucu/Documents/RL/Project
python eval_sac.py --best
```

---

## â“ FAQ

### Q: Am nevoie sÄƒ antrenez din nou SAC?
**A**: **NU!** DacÄƒ ai deja `sac_atc_best.pth`, poÈ›i evalua È™i vizualiza direct:
```bash
python eval_sac.py --best
python visualize_sac.py --best
```

### Q: Care model sÄƒ folosesc pentru evaluare?
**A**: **Ãntotdeauna `--best`**:
```bash
python eval_sac.py --best
python visualize_sac.py --best
```

### Q: CÃ¢t timp dureazÄƒ antrenamentul?
**A**: 
- Quick (100k): ~10-15 minute
- Full (500k): ~1-2 ore
- Long (1M): ~3-4 ore

### Q: Cum compar SAC cu PPO/DQN?
**A**: FoloseÈ™te script-ul de comparaÈ›ie:
```bash
python compare_all_agents.py
```

### Q: Pot relua antrenamentul de unde a rÄƒmas?
**A**: Da, modificÄƒ `train_sac.py` sÄƒ Ã®ncarce un checkpoint:
```python
agent.load("models/sac_checkpoints/sac_atc_500000.pth")
```

### Q: SAC este mai bun decÃ¢t PPO?
**A**: Depinde de task:
- **SAC** â†’ Mai sample efficient, explorare mai bunÄƒ
- **PPO** â†’ Mai simplu, mai stable pentru unele taskuri
- RuleazÄƒ `compare_all_agents.py` pentru a compara pe task-ul tÄƒu!

### Q: Cum vÄƒd progresul Ã®n timp real?
**A**: Logurile se salveazÄƒ Ã®n `atc_logs/`:
```bash
# Vezi ultimele linii
tail -f atc_logs/sac_training_*.log

# SAU foloseÈ™te TensorBoard (dacÄƒ e configurat)
tensorboard --logdir=atc_logs
```

---

## ğŸ“š Resurse Suplimentare

### DocumentaÈ›ie
- `SAC_CHEATSHEET.md` - Quick reference pentru comenzi
- `sac_agent.py` - Codul sursÄƒ cu comentarii detaliate

### Papers
- [Soft Actor-Critic (Original)](https://arxiv.org/abs/1801.01290)
- [SAC for Discrete Actions](https://arxiv.org/abs/1910.07207)

### Comenzi Utile Rapid

```bash
# Evaluare rapidÄƒ
python eval_sac.py --best --episodes 20

# Vizualizare
python visualize_sac.py --best

# ComparaÈ›ie modele
python eval_sac.py --compare

# Training nou (doar dacÄƒ e necesar!)
python train_sac.py --quick

# Test componente
python test_sac.py
```

---

## ğŸ¯ Quick Start pentru ÃncepÄƒtori

**EÈ™ti nou? UrmeazÄƒ aceÈ™ti paÈ™i:**

1. **ActiveazÄƒ environment-ul**:
   ```bash
   cd /Users/mihneacucu/Documents/RL/Project
   source venv/bin/activate
   ```

2. **EvalueazÄƒ modelul existent**:
   ```bash
   python eval_sac.py --best
   ```

3. **Vezi agentul Ã®n acÈ›iune**:
   ```bash
   python visualize_sac.py --best --episodes 3
   ```

4. **ComparÄƒ cu alte modele** (opÈ›ional):
   ```bash
   python eval_sac.py --compare
   ```

**Gata! Acum È™tii cum funcÈ›ioneazÄƒ SAC pe environment-ul tÄƒu!** ğŸš€

---

## ğŸ“§ Suport

Pentru Ã®ntrebÄƒri sau probleme:
1. VerificÄƒ secÈ›iunea [Troubleshooting](#troubleshooting)
2. VerificÄƒ FAQ-ul
3. RuleazÄƒ `python test_sac.py` pentru diagnosticare

---

**Happy Training! ğŸ‰**

